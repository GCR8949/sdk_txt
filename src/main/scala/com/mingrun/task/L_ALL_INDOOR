package com.mingrun.sdk.task

import com.mingrun.sdk.function.FieldsFunc._
import com.mingrun.sdk.function.JDBCFunc._
import org.apache.spark.broadcast.Broadcast
import org.apache.spark.rdd.RDD
import org.apache.spark.storage.StorageLevel
import org.apache.spark.{SparkConf, SparkContext}

/**
  * Created by GCR8949 on 2018/10/29.
  */
object L_ALL_INDOOR {

  def main(args: Array[String]): Unit = {
    //  判断合规log所需的最短字段要求
    val fieldsMinSize = 100
    //  源数据地址
    val dataPath = "G:\\TwoWF\\　　\\cell_in_0"
    //  栅格匹配省市的conf文件地址
    val confPath = "G:\\TwoWF\\　　\\conf.conf"
    //  栅格匹配场景的文件
    val gridPath = "G:\\TwoWF\\　　\\GRID_GROUP.csv"

    val conf = new SparkConf().setAppName("L_I_CLASS_40_640_1280_INDOOR").setMaster("local[4]")
    val sc = new SparkContext(conf)

    val dataRDD = sc.textFile(dataPath)
    val confRDD = sc.textFile(confPath)
    val gridRDD = sc.textFile(gridPath)

    val accum = new LocationAccumulator
    sc.register(accum, "locationAccum")

    //  加载已知的栅格与省市的匹配列表
    confRDD.foreach(line => {
      val items = line.split(",", -1)

      if (items.length == 3) {
        //  xyID_40 + province + city
        accum.add(items(0) + "|" + items(1) + "," + items(2))
      }
    })

    //  栅格编号匹配场景的map
    val gridMap = gridRDD.map(line => {
      val items = line.split(",", -1)
      //  PROVINCE + CITY + SCENE + GROUP_NAME + RTYPE + NRTYPE + GRID_ID
      if (items.length == 7) {
        (items(6), items(2) + "," + items(3))
      } else {
        null
      }
    }).filter(_ != null).collectAsMap()

    //  创建其广播变量
    val gridMapBroadcast = sc.broadcast(gridMap)

    /**
      * dataByXYIDRDD : (date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 ,　netType + netLevel + rsrp + sinr)
      */

    //  将原始数据转换为：栅格地域为key，其余信息为value的键值对RDD
    val dataByXYIDRDD = getDataByXYIDRDD(dataRDD, fieldsMinSize, accum).persist(StorageLevel.MEMORY_AND_DISK_SER)

    //  ----------------------------------------------------TRADTKPI----------------------------------------------------

    /**
      *  i_tradtkpiRDD : date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 + coverage_count + sinr_count + totalSmpl
      *
      *  i_tradtkpi_N_RDD : cdate + province + city + operator + xyID_N + overage_ratio + sinr3_ratio (40没有xyID_N)
      *
      *  i_tradtkpi_groupRDD : date + province + city + scene + group_name + operator + overage_ratio + sinr3_ratio
      */

    //  L_TRADTKPI_40_640_1280_INDOOR
    val i_tradtkpiRDD = getI_TradtKpiRDD(dataByXYIDRDD).persist(StorageLevel.MEMORY_AND_DISK_SER)

//    val sql_L_TRADTKPI_40_640_1280_INDOOR = "insert into L_TRADTKPI_40_640_1280_INDOOR values(to_date(?,'yyyy/mm/dd'),?,?,?,?,?,?,?,?,?)"
//    executeBatchByRDD(i_tradtkpiRDD, sql_L_TRADTKPI_40_640_1280_INDOOR, 10)

    // L_TRADTKPI_1280_DAY_INDOOR L_TRADTKPI_640_DAY_INDOOR  L_TRADTKPI_40_DAY_INDOOR
    val i_tradtkpi_1280RDD = getI_TradtKpi_N_RDD(i_tradtkpiRDD, 1280)
    val i_tradtkpi_640RDD = getI_TradtKpi_N_RDD(i_tradtkpiRDD, 640)
    val i_tradtkpi_40RDD = getI_TradtKpi_N_RDD(i_tradtkpiRDD, 40)

//    val sql_L_TRADTKPI_1280_DAY_INDOOR = "insert into L_TRADTKPI_1280_DAY_INDOOR (TIME_GRANULARITY, PROVINCE, CITY, OPERATOR, BLOCAKID1280, COVERAGE_RATIO, SINR3_RATIO) values(?,?,?,?,?,?,?)"
//    executeBatchByRDD(i_day_tradtkpi_1280RDD, sql_L_TRADTKPI_1280_DAY_INDOOR, 7)

//    val sql_L_TRADTKPI_640_DAY_INDOOR = "insert into L_TRADTKPI_640_DAY_INDOOR (TIME_GRANULARITY, PROVINCE, CITY, OPERATOR, BLOCAKID640, COVERAGE_RATIO, SINR3_RATIO) values(?,?,?,?,?,?,?)"
//    executeBatchByRDD(i_day_tradtkpi_640RDD, sql_L_TRADTKPI_640_DAY_INDOOR, 7)

//    val sql_L_TRADTKPI_40_DAY_INDOOR = "insert into L_TRADTKPI_40_DAY_INDOOR (TIME_GRANULARITY, PROVINCE, CITY, OPERATOR, COVERAGE_RATIO, SINR3_RATIO) values(?,?,?,?,?,?)"
//    executeBatchByRDD(i_day_tradtkpi_40RDD, sql_L_TRADTKPI_40_DAY_INDOOR, 6)

    i_tradtkpi_1280RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\kpi_1280_1")
    i_tradtkpi_640RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\kpi_640_1")
    i_tradtkpi_40RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\kpi_40_1")

    //  L_TRADTKPI_GROUP_DAY_INDOOR
    val i_tradtkpi_groupRDD = getI_TradtKpi_GroupRDD(i_tradtkpiRDD, gridMapBroadcast)

    i_tradtkpi_groupRDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\kpi_group1")

    //  释放不需要资源
    i_tradtkpiRDD.unpersist(true)

    //  ----------------------------------------------------L_I_CLASS---------------------------------------------------

    /**
      * proresRDD : date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 + totalSmpl + lteSmpl + outlineSmpl + G + B1 + B2
      *
      * i_N_RDD : date + province + city + operator + xyID_N + whole_ratio + build_ratio + optimization_ratio + not_four_g_ratio + not_network_ratio  (40没有xyID_N)
      *
      * i_groupRDD : date + province + city + scene + group_name + operator + whole_ratio + build_ratio + optimization_ratio + not_four_g_ratio + not_network_ratio
      */

    //  L_I_CLASS_40_640_1280_INDOOR
    val proresRDD = getProresRDD(dataByXYIDRDD).persist(StorageLevel.MEMORY_AND_DISK_SER)

    //  中间结果入库
//    val sql_L_I_40_640_1280_INDOOR_TEST = "insert into L_I_40_640_1280_INDOOR_TEST values(to_date(?,'yyyy/mm/dd '),?,?,?,?,?,?,?,?,?,?,?,?)"
//    executeBatchByRDD(proresRDD, sql_L_I_40_640_1280_INDOOR_TEST, 13)

//    proresRDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\prores1")

    val i_1280RDD = getI_N_RDD(proresRDD, 1280)
    val i_640RDD = getI_N_RDD(proresRDD, 640)
    val i_40RDD = getI_N_RDD(proresRDD, 40)

    i_1280RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\i_1280_1")
    i_640RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\i_640_1")
    i_40RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\i_40_1")

    //  L_I_CLASS_GROUP_DAY_INDOOR
    val i_groupRDD = getI_GroupRDD(proresRDD, gridMapBroadcast)

    i_groupRDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\i_group1")

    //  释放不需要资源
    proresRDD.unpersist(true)

    //  ---------------------------------------------------L_II_CLASS---------------------------------------------------

    /**
      * prores2RDD : date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 + lteSmpl + N1 + N2
      *
      * ii_N_RDD : date + province + city + operator + xyID_N + build_ratio + optimization_ratio  (40没有xyID_N)
      *
      *
      */

    //  L_II_CLASS_40_640_1280_INDOOR
    val prores2RDD = getProres2RDD(dataByXYIDRDD).persist(StorageLevel.MEMORY_AND_DISK_SER)
//    prores2RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\ii_1")

    //  释放不需要资源
    dataByXYIDRDD.unpersist(true)

    val ii_1280RDD = getII_N_RDD(prores2RDD, 1280)
    val ii_640RDD = getII_N_RDD(prores2RDD, 640)
    val ii_40RDD = getII_N_RDD(prores2RDD, 40)

    ii_1280RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\ii_1280_1")
    ii_640RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\ii_640_1")
    ii_40RDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\ii_40_1")

    val ii_groupRDD = getII_GroupRDD(prores2RDD, gridMapBroadcast)

    ii_groupRDD.coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\ii_group1")

    //  释放不需要资源
    prores2RDD.unpersist(true)

    //  -----------------------------------------------------OTHER------------------------------------------------------

//    sc.parallelize(accum.value.toList).map(x => x._1 + "," + x._2).coalesce(1).saveAsTextFile("G:\\TwoWF\\　　\\conf1")
  }


  //  ---------------------------------------------------UsualFuncion---------------------------------------------------


  /**
    * 对同地域下的数据做统计产生中间结果RDD
    * @param dataByXYIDRDD  栅格地域为key，其余信息为value的键值对RDD的byKey聚合
    * @return 中间结果RDD
    */
  def getProresRDD(dataByXYIDRDD: RDD[(String, scala.Iterable[String])]): RDD[String] = {
    dataByXYIDRDD.mapValues(lines => {
      var totalSmpl = 0L
      var lteSmpl = 0L
      var outlineSmpl = 0L
      var G = 0L
      var B1 = 0L
      var B2 = 0L

      val list = lines.toList

      list.foreach(line => {
        val items = line.split(",", -1)

        val netType = items(0)
        val netLevel = items(1)

        if ("LTE".equals(netType)) {
          lteSmpl = lteSmpl + 1L
        } else if ("".equals(netType)) {
          outlineSmpl = outlineSmpl + 1L
        }

        if ("G".equals(netLevel)) {
          G = G + 1L
        } else if ("B1".equals(netLevel)) {
          B1 = B1 + 1L
        } else if ("B2".equals(netLevel)) {
          B2 = B2 + 1L
        }

        totalSmpl = totalSmpl + 1L
      })

      totalSmpl + "," + lteSmpl + "," + outlineSmpl + "," + G + "," + B1 + "," + B2
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * 对同地域下的数据做统计产生中间结果RDD
    * @param dataByXYIDRDD  栅格地域为key，其余信息为value的键值对RDD的byKey聚合
    * @return 中间结果RDD
    */
  def getProres2RDD(dataByXYIDRDD: RDD[(String, scala.Iterable[String])]): RDD[String] = {
    dataByXYIDRDD.mapValues(lines => {
      var lteSmpl = 0L
      var N1 = 0L
      var N2 = 0L

      val list = lines.toList

      list.foreach(line => {
        val items = line.split(",", -1)

        val netType = items(0)
        val rsrp = items(2).toInt
        val sinr = items(3).toInt

        if ("LTE".equals(netType)) {
          lteSmpl = lteSmpl + 1L

          if (rsrp < -110 && sinr > 0 && sinr < 1000) {
            N1 = N1 + 1L
          }

          if (rsrp > -100 && sinr > 0 && sinr < 1000 && rsrp < 1000) {
            N2 = N2 + 1L
          }
        }

      })

      lteSmpl + "," + N1 + "," + N2
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * resRDD : date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 + lteSmpl + N1 + N2
    * 根据不同的栅格大小，从中间结果RDD中获取不同数据
    * @param prores2RDD 中间结果RDD
    * @param gridSize 栅格大小
    * @return 对应栅格大小的数据
    */
  def getII_N_RDD(prores2RDD: RDD[String], gridSize: Int): RDD[String] = {
    val n = gridSize match {
      case 1280 => 4
      case 640 => 5
      case _ => -1
    }

    prores2RDD.map(line => {
      val items = line.split(",", -1)

      val date = items(0)
      val province = items(1)
      val city = items(2)
      val operator = items(3)
      val lteSmpl = items(7)
      val N1 = items(8)
      val N2 = items(9)

      var key = date + "," + province + "," + city + "," + operator

      if (n != -1) {
        val xyID_N = items(n)
        key = key + "," + xyID_N
      }

      val value = lteSmpl + "," + N1 + "," + N2

      (key, value)
    }).groupByKey().mapValues(x => {
      val datas = x.toList
      val datasCount = datas.size
      var i = 0L
      var j = 0L

      datas.foreach(data => {
        val items = data.split(",", -1)

        val lteSmpl = items(0).toLong
        val N1 = items(1).toLong
        val N2 = items(2).toLong

        if (lteSmpl != 0) {
          if (N1 * 1.0 / lteSmpl > 0.02) i = i + 1L
          if (N2 * 1.0 / lteSmpl > 0.02) j = j + 1L
        }
      })

      val build_ratio = if (datasCount != 0) {
        (i * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val optimization_ratio = if (datasCount != 0) {
        (j * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      build_ratio + "," + optimization_ratio
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * 对同地域下的数据做统计产生中间结果RDD
    * @param dataByXYIDRDD  栅格地域为key，其余信息为value的键值对RDD的byKey聚合
    * @return i_tradtkpi的中间结果表
    */
  def getI_TradtKpiRDD(dataByXYIDRDD: RDD[(String, scala.Iterable[String])]): RDD[String] = {
    dataByXYIDRDD.mapValues(lines => {
      var totalSmpl = 0L
      var coverage_count = 0L
      var sinr_count = 0L

      val list = lines.toList

      list.foreach(line => {
        val items = line.split(",", -1)

        val rsrp = items(2).toInt
        val sinr = items(3).toInt

        if (rsrp < -2 && sinr < 1000) {
          if (rsrp > -105 && sinr > -3) {
            coverage_count = coverage_count + 1L
          }

          if (sinr > 3) {
            sinr_count = sinr_count + 1L
          }

          totalSmpl = totalSmpl + 1L
        }
      })

      coverage_count + "," + sinr_count + "," + totalSmpl

    }).map(x => x._1 + "," + x._2)
  }

  /**
    * i_tradtkpiRDD : date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 + coverage_count + sinr_count + totalSmpl
    * 根据不同的栅格大小，从中间结果RDD中获取不同数据
    * @param i_tradtkpiRDD  中间结果RDD
    * @param gridSize 栅格大小
    * @return 对应栅格大小的数据
    */
  def getI_TradtKpi_N_RDD(i_tradtkpiRDD: RDD[String], gridSize: Int): RDD[String] = {
    val n = gridSize match {
      case 1280 => 4
      case 640 => 5
      case _ => -1
    }

    i_tradtkpiRDD.map(line => {
      val items = line.split(",", -1)

      val date = items(0)
      val province = items(1)
      val city = items(2)
      val operator = items(3)
      val coverage_count = items(7)
      val sinr_count = items(8)
      val totalSmpl = items(9)

      var key = date + "," + province + "," + city + "," + operator

      if (n != -1) {
        val xyID_N = items(n)
        key = key  + "," + xyID_N
      }

      val value = coverage_count + "," + sinr_count + "," + totalSmpl

      (key, value)
    }).groupByKey().mapValues(x => {
      val datas = x.toList

      var all_coverage_count = 0L
      var all_sinr_count = 0L
      var all_totalSmpl = 0L

      datas.foreach(data => {
        val items = data.split(",", -1)
        val coverage_count = items(0).toLong
        val sinr_count = items(1).toLong
        val totalSmpl = items(2).toLong

        all_coverage_count = all_coverage_count + coverage_count
        all_sinr_count = all_sinr_count + sinr_count
        all_totalSmpl = all_totalSmpl + totalSmpl
      })

      val coverage_ratio = if (all_totalSmpl != 0) {
        (all_coverage_count * 100.0 / all_totalSmpl).formatted("%.2f")
      } else "0.00"

      val sinr3_ratio =  if (all_totalSmpl != 0) {
        (all_sinr_count * 100.0 / all_totalSmpl).formatted("%.2f")
      } else "0.00"

      coverage_ratio + "," + sinr3_ratio
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * 将原始数据转换为：栅格地域为key，其余信息为value的键值对RDD的byKey聚合
    * @param dataRDD  原始数据RDD
    * @param fieldsMinSize  判断合规log所需的最短字段要求
    * @param accum  栅格对应省市的累加器
    * @return 栅格地域为key，其余信息为value的键值对RDD的byKey聚合
    */
  def getDataByXYIDRDD(dataRDD: RDD[String], fieldsMinSize: Int, accum: LocationAccumulator): RDD[(String, scala.Iterable[String])] = {
    dataRDD.map(line => {
      var resStr: (String, String) = null

      if (line != null && ! line.equals("")) {
        val items = line.split(",", -1)

        if (items.length >= fieldsMinSize) {
          val lng = lngLatStr2Double(items(10))
          val lat = lngLatStr2Double(items(9))

          if (lng != 0.0 && lat != 0.0) {
            val xyID_40 = getXYID(lng, lat, 40)

            var locationRight = true
            val xyID_640 = getXYID(lng, lat, 640)
            val xyID_1280 = getXYID(lng, lat, 1280)

            var province = lengthCorrection(fieldNull2Unknown(items(14)), 100)
            var city = lengthCorrection(fieldNull2Unknown(items(15)), 100)

            /**
            针对有些log中没有省市的情况，使用其经纬度来重新获取
              但如果遇到网络问题等，在尝试获取默认次数仍然失败时
              则省市为“UNKNOWN”
              ----------------------------------------------------------
              已更新：
              鉴于没有省市的数据为少数，且通过其经纬度查询地址需要走网络
              这其中就加大了不少的资源消耗，降低了效率
              目前采用40栅格（40m * 40m）匹配已知省市做缓存，对于相同栅格内
              没有省市的情况做匹配处理，秉承着大数据下忽略个例的方针
              未匹配到的暂时舍弃
              ----------------------------------------------------------
              后面打算将每次的已知匹配表做存储并持续更新
              以达到尽可能匹配到所有已知区域
              */
            if ("UNKNOWN".equals(province) || "UNKNOWN".equals(city)) {
              val proAndcity = accum.value.getOrElse(xyID_40, null)

              if (proAndcity != null) {
                val location = proAndcity.split(",", -1)
                province = location(0)
                city = location(1)
              } else {
                //  未匹配到location，暂时舍弃
                locationRight = false
              }
            } else {
              accum.add(xyID_40 + "|" + province + "," + city)
            }

            if (locationRight) {
              val date = timestamp2Date(items(19))
              val operator = lengthCorrection(fieldNull2Unknown(items(29)), 100)
              val netType = items(31)
              val rsrp = rsrpSinrStr2Int(items(35))
              val sinr = rsrpSinrStr2Int(items(36))

              //  如果rsrp或sinr不合规，后续不参与网络情况的计算和统计
              var netLevel = "0"

              if (rsrp < 1000 && sinr < 1000) {
                if (rsrp >= -100 && sinr >= 3) netLevel = "G"
                if (rsrp >= -100 && sinr <= 0) netLevel = "B1"
                if (rsrp <= -110 && sinr <= 0) netLevel = "B2"
              }

              val key = date + "," + province + "," + city + "," + operator + "," + xyID_1280 + "," + xyID_640 + "," + xyID_40
              val value = netType + "," + netLevel + "," + rsrp + "," + sinr

              resStr = (key , value)
            } else {
              //  未匹配到location，暂时舍弃
            }
          } else {
            //  作为必要字段的经纬度存在不合规的情况
          }
        } else {
          //  log字段小于最短字段要求
        }
      } else {
        //  log不合规
      }

      resStr
    }).filter(_ != null).groupByKey()
  }

  /**
    * resRDD : date + province + city + operator + xyID_1280 + xyID_640 + xyID_40 + totalSmpl + lteSmpl + outlineSmpl + G + B1 + B2
    * 根据不同的栅格大小，从中间结果RDD中获取不同数据
    * @param proresRDD 中间结果RDD
    * @param gridSize 栅格大小
    * @return 对应栅格大小的数据
    */
  def getI_N_RDD(proresRDD: RDD[String], gridSize: Int): RDD[String] = {
    val n = gridSize match {
      case 1280 => 4
      case 640 => 5
      case _ => -1
    }

    proresRDD.map(line => {
      val items = line.split(",", -1)

      val date = items(0)
      val province = items(1)
      val city = items(2)
      val operator = items(3)
      val totalSmpl = items(7)
      val lteSmpl = items(8)
      val outlineSmpl = items(9)
      val G = items(10)
      val B1 = items(11)
      val B2 = items(12)

      var key = date + "," + province + "," + city + "," + operator

      if (n != -1) {
        val xyID_N = items(n)
        key = key + "," + xyID_N
      }

      val value = totalSmpl + "," + lteSmpl + "," + outlineSmpl + "," + G + "," + B1 + "," + B2

      (key, value)
    }).groupByKey().mapValues(x => {
      val datas = x.toList
      val datasCount = datas.size
      var allTotalSmpl = 0L
      var allLteSmpl = 0L
      var allOutlineSmpl = 0L
      var i = 0L
      var j = 0L
      var k = 0L

      datas.foreach(data => {
        val items = data.split(",", -1)

        val totalSmpl = items(0).toLong
        val lteSmpl = items(1).toLong
        val outlineSmpl = items(2).toLong
        val G = items(3).toLong
        val B1 = items(4).toLong
        val B2 = items(5).toLong

        allTotalSmpl = allTotalSmpl + totalSmpl
        allLteSmpl = allLteSmpl + lteSmpl
        allOutlineSmpl = allOutlineSmpl + outlineSmpl

        if (totalSmpl != 0) {
          if ((G - B1 - B2) * 1.0 / totalSmpl > 0.85) i = i + 1L
          if (B2 * 1.0 / totalSmpl > 0.85) j = j + 1L
          if (B1 * 1.0 / totalSmpl > 0.85) k = k + 1L
        }

      })

      val whole_ratio = if (datasCount != 0) {
        (i * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val build_ratio = if (datasCount != 0) {
        (j * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val optimization_ratio = if (datasCount != 0) {
        (k * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val not_four_g_ratio = if (allTotalSmpl != 0) {
        ((allTotalSmpl - allLteSmpl) * 100.0 / allTotalSmpl).formatted("%.2f")
      } else "0.00"

      val not_network_ratio = if (allTotalSmpl != 0) {
        (allOutlineSmpl * 100.0 / allTotalSmpl).formatted("%.2f")
      } else "0.00"

      whole_ratio + "," + build_ratio + "," + optimization_ratio + "," + not_four_g_ratio + "," + not_network_ratio
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * 使用40栅格编号匹配该区域场景名称，并对该区域下数据做统计计算
    * @param i_tradtkpiRDD  中间结果RDD
    * @param gridMapBroadcast 40栅格编号匹配区域场景的广播变量
    * @return 各个场景下的数据统计结果
    */
  def getI_TradtKpi_GroupRDD(i_tradtkpiRDD: RDD[String], gridMapBroadcast: Broadcast[scala.collection.Map[String, String]]): RDD[String] = {
    i_tradtkpiRDD.map(line => {
      val items = line.split(",", -1)

      val xyID_40 = items(6)

      val gridMap = gridMapBroadcast.value

      val gridData = gridMap.getOrElse(xyID_40, null)

      if (gridData != null) {
        val scenes = gridData.split(",", -1)

        val scene = scenes(0)
        val group_name = scenes(1)

        val date = items(0)
        val province = items(1)
        val city = items(2)
        val operator = items(3)
        val coverage_count = items(7)
        val sinr_count = items(8)
        val totalSmpl = items(9)

        val key = date + "," + province + "," + city + "," + scene + "," + group_name + "," + operator
        val value = coverage_count + "," + sinr_count + "," + totalSmpl
        (key, value)
      } else {
        null
      }
    }).filter(_ != null).groupByKey().mapValues(x => {
      val datas = x.toList

      var all_coverage_count = 0L
      var all_sinr_count = 0L
      var all_totalSmpl = 0L

      datas.foreach(data => {
        val items = data.split(",", -1)
        val coverage_count = items(0).toLong
        val sinr_count = items(1).toLong
        val totalSmpl = items(2).toLong

        all_coverage_count = all_coverage_count + coverage_count
        all_sinr_count = all_sinr_count + sinr_count
        all_totalSmpl = all_totalSmpl + totalSmpl
      })

      val coverage_ratio = if (all_totalSmpl != 0) {
        (all_coverage_count * 100.0 / all_totalSmpl).formatted("%.2f")
      } else "0.00"

      val sinr3_ratio = if (all_totalSmpl != 0) {
        (all_sinr_count * 100.0 / all_totalSmpl).formatted("%.2f")
      } else "0.00"

      coverage_ratio + "," + sinr3_ratio
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * 使用40栅格编号匹配该区域场景名称，并对该区域下数据做统计计算
    * @param prores2RDD  中间结果RDD
    * @param gridMapBroadcast 40栅格编号匹配区域场景的广播变量
    * @return 各个场景下的数据统计结果
    */
  def getI_GroupRDD(prores2RDD: RDD[String], gridMapBroadcast: Broadcast[scala.collection.Map[String, String]]): RDD[String] = {
    prores2RDD.map(line => {
      val items = line.split(",", -1)

      val xyID_40 = items(6)

      val gridMap = gridMapBroadcast.value

      val gridData = gridMap.getOrElse(xyID_40, null)

      if (gridData != null) {
        val scenes = gridData.split(",", -1)

        val scene = scenes(0)
        val group_name = scenes(1)

        val date = items(0)
        val province = items(1)
        val city = items(2)
        val operator = items(3)
        val totalSmpl = items(7)
        val lteSmpl = items(8)
        val outlineSmpl = items(9)
        val G = items(10)
        val B1 = items(11)
        val B2 = items(12)

        val key = date + "," + province + "," + city + "," + scene + "," + group_name + "," + operator
        val value = totalSmpl + "," + lteSmpl + "," + outlineSmpl + "," + G + "," + B1 + "," + B2
        (key, value)
      } else {
        null
      }
    }).filter(_ != null).groupByKey().mapValues(x => {
      val datas = x.toList
      val datasCount = datas.size
      var allTotalSmpl = 0L
      var allLteSmpl = 0L
      var allOutlineSmpl = 0L
      var i = 0L
      var j = 0L
      var k = 0L

      datas.foreach(data => {
        val items = data.split(",", -1)

        val totalSmpl = items(0).toLong
        val lteSmpl = items(1).toLong
        val outlineSmpl = items(2).toLong
        val G = items(3).toLong
        val B1 = items(4).toLong
        val B2 = items(5).toLong

        allTotalSmpl = allTotalSmpl + totalSmpl
        allLteSmpl = allLteSmpl + lteSmpl
        allOutlineSmpl = allOutlineSmpl + outlineSmpl

        if (totalSmpl != 0) {
          if ((G - B1 - B2) * 1.0 / totalSmpl > 0.85) i = i + 1L
          if (B2 * 1.0 / totalSmpl > 0.85) j = j + 1L
          if (B1 * 1.0 / totalSmpl > 0.85) k = k + 1L
        }

      })

      val whole_ratio = if (datasCount != 0) {
        (i * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val build_ratio = if (datasCount != 0) {
        (j * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val optimization_ratio = if (datasCount != 0) {
        (k * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val not_four_g_ratio = if (allTotalSmpl != 0) {
        ((allTotalSmpl - allLteSmpl) * 100.0 / allTotalSmpl).formatted("%.2f")
      } else "0.00"

      val not_network_ratio = if (allTotalSmpl != 0) {
        (allOutlineSmpl * 100.0 / allTotalSmpl).formatted("%.2f")
      } else "0.00"

      whole_ratio + "," + build_ratio + "," + optimization_ratio + "," + not_four_g_ratio + "," + not_network_ratio
    }).map(x => x._1 + "," + x._2)
  }

  /**
    * 使用40栅格编号匹配该区域场景名称，并对该区域下数据做统计计算
    * @param proresRDD  中间结果RDD
    * @param gridMapBroadcast 40栅格编号匹配区域场景的广播变量
    * @return 各个场景下的数据统计结果
    */
  def getII_GroupRDD(proresRDD: RDD[String], gridMapBroadcast: Broadcast[scala.collection.Map[String, String]]): RDD[String] = {
    proresRDD.map(line => {
      val items = line.split(",", -1)

      val xyID_40 = items(6)

      val gridMap = gridMapBroadcast.value

      val gridData = gridMap.getOrElse(xyID_40, null)

      if (gridData != null) {
        val scenes = gridData.split(",", -1)

        val scene = scenes(0)
        val group_name = scenes(1)

        val date = items(0)
        val province = items(1)
        val city = items(2)
        val operator = items(3)
        val lteSmpl = items(7)
        val N1 = items(8)
        val N2 = items(9)

        val key = date + "," + province + "," + city + "," + scene + "," + group_name + "," + operator
        val value = lteSmpl + "," + N1 + "," + N2
        (key, value)
      } else {
        null
      }
    }).filter(_ != null).groupByKey().mapValues(x => {
      val datas = x.toList
      val datasCount = datas.size
      var i = 0L
      var j = 0L

      datas.foreach(data => {
        val items = data.split(",", -1)

        val lteSmpl = items(0).toLong
        val N1 = items(1).toLong
        val N2 = items(2).toLong

        if (lteSmpl != 0) {
          if (N1 * 1.0 / lteSmpl > 0.02) i = i + 1L
          if (N2 * 1.0 / lteSmpl > 0.02) j = j + 1L
        }
      })

      val build_ratio = if (datasCount != 0) {
        (i * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      val optimization_ratio = if (datasCount != 0) {
        (j * 100.0D / datasCount).formatted("%.2f")
      } else "0.00"

      build_ratio + "," + optimization_ratio
    }).map(x => x._1 + "," + x._2)
  }

  //  --------------------------------------------------SpecialFuncion--------------------------------------------------


}
